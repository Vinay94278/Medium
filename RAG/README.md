# RAG (Retrieval-Augmented Generation) App

A modular, scalable Streamlit application for document ingestion, chunking, embedding, and retrieval using state-of-the-art LLMs via ChatGroq. Designed for flexibility, robust error handling, and easy extension.

---

## ğŸš€ Features

- **PDF Upload & Ingestion:** Upload one or more PDFs (â‰¤25MB each) for processing.
- **Document Chunking:** Splits documents into manageable chunks for efficient retrieval.
- **Embeddings & Vector Store:** Embeds chunks and stores them in a Chroma vector database.
- **Dynamic LLM Selection:** Choose from multiple free ChatGroq models, set temperature, and max tokens.
- **Rate Limit Awareness:** Displays model-specific rate limits (RPM, RPD, TPM, TPD).
- **Custom Exception Handling:** Robust, extensible error handling for files, database, and application logic.
- **Configurable & Maintainable:** Centralized constants, messages, and configuration.
- **User API Key Input:** Securely enter your own ChatGroq API key.

---

## ğŸ—‚ï¸ Project Structure

```
RAG/
â”‚
â”œâ”€â”€ app.py                  # Main Streamlit app
â”œâ”€â”€ config/                 # Configuration, constants, messages
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ constants.py
â”‚   â””â”€â”€ messages.py
â”‚
â”œâ”€â”€ core/                   # Core logic modules
â”‚   â”œâ”€â”€ loader.py
â”‚   â”œâ”€â”€ splitter.py
â”‚   â”œâ”€â”€ embedder.py
â”‚   â”œâ”€â”€ prompt.py
â”‚   â”œâ”€â”€ llm.py
â”‚   â””â”€â”€ output_parser.py
â”‚
â”œâ”€â”€ exceptions/             # Custom exception classes
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ application_exception.py
â”‚   â”œâ”€â”€ database_exception.py
â”‚   â””â”€â”€ file_exception.py
â”‚
â”œâ”€â”€ store/                  # Chroma vector store (auto-generated)
â”œâ”€â”€ docs/                   # Documentation
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md               # Project overview
```

---

## ğŸ Getting Started

### 1. **Clone the Repository**
```sh
git clone https://github.com/yourusername/rag-app.git
cd rag-app
```

### 2. **Install Dependencies**
```sh
python -m venv .venv
.venv\Scripts\activate  # On Windows
pip install -r requirements.txt
```

### 3. **Run the App**
```sh
streamlit run app.py
```

---

## âš™ï¸ Configuration

- **API Key:** Enter your ChatGroq API key in the sidebar.
- **Model Selection:** Choose from available free ChatGroq models.
- **Temperature & Max Tokens:** Adjust generation parameters in the sidebar.

---

## ğŸ§© Core Modules

- **`core/loader.py`**  
  Loads and parses PDF files.
- **`core/splitter.py`**  
  Splits documents into chunks for embedding.
- **`core/embedder.py`**  
  Embeds chunks and stores them in Chroma.
- **`core/prompt.py`**  
  Loads and formats prompts for the LLM.
- **`core/llm.py`**  
  Initializes the ChatGroq LLM with user parameters.
- **`core/output_parser.py`**  
  Parses and formats LLM outputs.

---

## ğŸ›¡ï¸ Exception Handling

- **`exceptions/application_exception.py`**  
  Base class for all custom exceptions.
- **`exceptions/database_exception.py`**  
  Handles database/vector store errors.
- **`exceptions/file_exception.py`**  
  Handles file loading and parsing errors.

All exceptions are caught and displayed as user-friendly messages in the UI.

---

## ğŸ“ Customization

- **Add More Models:**  
  Update `config/constants.py` with new models and their rate limits.
- **Change Chunk Size:**  
  Adjust `CHUNK_SIZE` and `CHUNK_OVERLAP` in `constants.py`.
- **Extend Exception Handling:**  
  Add new exception classes in `exceptions/`.

---

## ğŸ¤ Contributing

1. Fork the repo
2. Create a feature branch
3. Commit your changes
4. Open a pull request

---

## ğŸ™‹ FAQ

**Q:** Why do I get a "dimension mismatch" error?  
**A:** Delete the `store/` directory if you change embedding models.

**Q:** How do I add a new LLM?  
**A:** Add it to `config/constants.py` and update the sidebar logic in `app.py`.

---

## ğŸ“¬ Contact

For questions or support, open an issue